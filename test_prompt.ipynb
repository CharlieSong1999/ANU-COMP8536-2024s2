{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/kf09/lz1278/lyenv/flash3d/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./flash3d')\n",
    "sys.path.append('./flash3d/flash3d')\n",
    "from flash3d.generator_test import Flash3DReconstructor\n",
    "import torch\n",
    "import types\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from flash3d.flash3d.util.export_param import postprocess\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from vlm_diffusion_pipeline import main as generate_diffusion_img\n",
    "from matplotlib import pyplot as plt\n",
    "from diffusers.utils import load_image, make_image_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the input image and the output directory, the input image is the very first image of the whole pipeline\n",
    "intial_img_path = './flash3d/frame000652.jpg'\n",
    "output_path = './flash3d-output'\n",
    "current_directory = './flash3d-cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.2.2+cu121 with CUDA 1201 (you have 2.2.2)\n",
      "    Python  3.11.8 (you have 3.11.10)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "Triton is not available, some optimizations will not be enabled.\n",
      "This is just a warning: triton is not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiate: dinov2_vitl14\n"
     ]
    }
   ],
   "source": [
    "# Define the model, from Jiaqi's code at /flash3d/generator_test.py\n",
    "flash3dreconstructor = Flash3DReconstructor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the decorator to add the function to the instance of the reconstructor\n",
    "def decorator_add_function_to_instance(instance, func):\n",
    "    setattr(instance, func.__name__, types.MethodType(func, instance))\n",
    "\n",
    "setattr(flash3dreconstructor, 'add_function_to_instance', types.MethodType(decorator_add_function_to_instance, flash3dreconstructor))\n",
    "\n",
    "# Preprocess the input image, get the flash3d output, then the postprocess\n",
    "@flash3dreconstructor.add_function_to_instance\n",
    "def flash3d_postprocess(self, index, image):\n",
    "    if (index == 0):\n",
    "        image = self.to_tensor(image).to(self.device).unsqueeze(0)\n",
    "\n",
    "    else:\n",
    "        image = self.diffusion_img\n",
    "\n",
    "    save_image(image, current_directory+f\"/imgs/{index}_inputpre.png\")\n",
    "    self.gt_img.append(image)\n",
    "\n",
    "    inputs = {\n",
    "        (\"color_aug\", 0, 0): image,\n",
    "    }\n",
    "\n",
    "    # flash3d输出\n",
    "    result = self.model(inputs)\n",
    "\n",
    "    # 2层3dg\n",
    "    outputs = postprocess(result,\n",
    "                        num_gauss=2,\n",
    "                        h=self.cfg.dataset.height,\n",
    "                        w=self.cfg.dataset.width,\n",
    "                        pad=self.cfg.dataset.pad_border_aug)\n",
    "    # 1层3dg\n",
    "    outputs_1_gauss = postprocess(result,\n",
    "                        num_gauss=1,\n",
    "                        h=self.cfg.dataset.height,\n",
    "                        w=self.cfg.dataset.width,\n",
    "                        pad=self.cfg.dataset.pad_border_aug)\n",
    "    \n",
    "    return outputs, outputs_1_gauss\n",
    "\n",
    "# 处理初始输入图片，添加到地图中\n",
    "# Directly copy from Jiaqi's code\n",
    "@flash3dreconstructor.add_function_to_instance\n",
    "def flash3d_initial_map(self, outputs, outputs_1_gauss):\n",
    "    self.map_param_2 = outputs\n",
    "    self.map_param_2['rotations'] = torch.tensor(self.map_param_2['rotations']).to('cuda')\n",
    "\n",
    "    self.map_param_1 = outputs_1_gauss\n",
    "    self.map_param_1['rotations'] = torch.tensor(self.map_param_1['rotations']).to('cuda')\n",
    "\n",
    "    self.map_param_2 = self.optimize_map(self.map_param_2)\n",
    "\n",
    "# 处理生成的图片，按照mask添加新元素，变换到世界坐标下，添加到地图中\n",
    "# Directly copy from Jiaqi's code\n",
    "@flash3dreconstructor.add_function_to_instance\n",
    "def flash3d_additional_map(self, index, outputs, outputs_1_gauss):\n",
    "    w2c = self.w2c[index]\n",
    "\n",
    "    self.cur_param_2 = outputs\n",
    "    self.cur_param_2['rotations'] = torch.tensor(self.cur_param_2['rotations']).to('cuda')\n",
    "\n",
    "    self.cur_param_1 = outputs_1_gauss\n",
    "    self.cur_param_1['rotations'] = torch.tensor(self.cur_param_1['rotations']).to('cuda')\n",
    "\n",
    "    c2w = torch.inverse(w2c)\n",
    "    self.cur_param_1['means'] = self.apply_transformation(self.cur_param_1['means'], c2w.to('cuda'))\n",
    "    self.cur_param_2['means'] = self.apply_transformation(self.cur_param_2['means'], c2w.to('cuda'))\n",
    "\n",
    "    # 保留新增的部分\n",
    "    mask = ~torch.tensor(self.mask).view(-1)\n",
    "    mask_2 = mask.repeat(2)\n",
    "    # update global map\n",
    "    for key in self.map_param_1.keys():\n",
    "\n",
    "        original_tensor = self.map_param_1[key].to('cuda')\n",
    "        updated_tensor = torch.tensor(self.cur_param_1[key]).to('cuda')\n",
    "        updated_tensor = updated_tensor[mask]\n",
    "\n",
    "        if isinstance(updated_tensor, np.ndarray):\n",
    "            updated_tensor = torch.tensor(updated_tensor).to('cuda')\n",
    "\n",
    "        self.map_param_1[key] = torch.cat((original_tensor, updated_tensor), dim=0)\n",
    "\n",
    "        original_tensor = self.map_param_2[key].to('cuda')\n",
    "        updated_tensor = torch.tensor(self.cur_param_2[key]).to('cuda')\n",
    "        updated_tensor = updated_tensor[mask_2]\n",
    "\n",
    "        if isinstance(updated_tensor, np.ndarray):\n",
    "            updated_tensor = torch.tensor(updated_tensor).to('cuda')\n",
    "\n",
    "        self.map_param_2[key] = torch.cat((original_tensor, updated_tensor), dim=0)\n",
    "\n",
    "    self.map_param_2 = self.optimize_map(self.map_param_2)\n",
    "\n",
    "@flash3dreconstructor.add_function_to_instance\n",
    "def flash3d_prepare_img_mask_for_diffusion(self, index):\n",
    "    # 新视角下渲染\n",
    "    w2c = self.w2c[index+1]\n",
    "    im_original, radius = self.renderer.render(self.map_param_2, w2c)\n",
    "    im = im_original[:, 32:352, 32:608]\n",
    "    self.renderer.save_image(im, current_directory+f\"/imgs/{index}_render_2gauss.png\")\n",
    "\n",
    "    # render 1 gauss per pixel\n",
    "    im_1_gauss_original, radius = self.renderer.render(self.map_param_1, w2c)\n",
    "    im_1_gauss = im_1_gauss_original[:, 32:352, 32:608]\n",
    "    self.renderer.save_image(im_1_gauss, current_directory+f\"/imgs/{index}_render_1gauss.png\")\n",
    "\n",
    "    image_a_pil = to_pil_image(im_1_gauss)\n",
    "    image_b_pil = to_pil_image(im)\n",
    "    masked_img, mask = self.apply_mask_from_images(image_a_pil, image_b_pil)\n",
    "\n",
    "    self.mask = mask # mask for the diffusion and adding new 3dg\n",
    "    mask_render_path = current_directory+f\"/imgs/{index}_masked_rendered.png\"\n",
    "    self.renderer.save_image(masked_img, mask_render_path)\n",
    "\n",
    "    # 获取diffusion的mask\n",
    "    image_a_pil = to_pil_image(im_1_gauss_original)\n",
    "    image_b_pil = to_pil_image(im_original)\n",
    "    masked_img_diffusion, mask_diffusion = self.apply_mask_from_images(image_a_pil, image_b_pil)\n",
    "    mask_diffusion = ~torch.tensor(mask_diffusion)\n",
    "    mask_diffusion = mask_diffusion.to(torch.float32)\n",
    "\n",
    "\n",
    "    # input of diffusion\n",
    "    mask_render_path_diffusion = current_directory+f\"/imgs/{index}_masked_rendered_original.png\"\n",
    "    self.renderer.save_image(masked_img_diffusion, mask_render_path_diffusion)\n",
    "    mask_path_diffusion = current_directory+f\"/imgs/{index}_mask_diffusion.png\"\n",
    "    self.renderer.save_image(mask_diffusion, mask_path_diffusion)\n",
    "\n",
    "    return mask_render_path_diffusion, mask_path_diffusion\n",
    "\n",
    "@flash3dreconstructor.add_function_to_instance\n",
    "def flash3d_post_process_diffusion_img(self, diffusion_img):\n",
    "    transform = transforms.Compose([\n",
    "                transforms.Resize((384, 640)),  # 先调整大小为 (height, width)\n",
    "                transforms.CenterCrop((320, 576)),  # 再中心裁剪为 (height, width)\n",
    "                transforms.Pad(padding=32, fill=(0, 0, 0))  # 最后添加 32 像素的填充，填充颜色为黑色\n",
    "            ])\n",
    "    diffusion_img = transform(diffusion_img)\n",
    "\n",
    "    self.diffusion_img = self.to_tensor(diffusion_img).to(self.device).unsqueeze(0) # [1, 3, 384, 640]\n",
    "\n",
    "@flash3dreconstructor.add_function_to_instance\n",
    "def flash3d_final_process(self, ):\n",
    "    reconstructor = self\n",
    "    # 优化1 layer的map\n",
    "    reconstructor.map_param_1 = reconstructor.optimize_map(reconstructor.map_param_1)\n",
    "\n",
    "    # 不同视角渲染地图并保存\n",
    "    for i in range(15, -1, -1):\n",
    "        temp_w2c = reconstructor.get_SE3_rotation_y(i)\n",
    "\n",
    "        im, radius = reconstructor.renderer.render(reconstructor.map_param_1, temp_w2c)\n",
    "        im = im[:, 32:352, 32:608]\n",
    "        reconstructor.renderer.save_image(im, current_directory+f'/rotate_demo/{15-i}_render.png')\n",
    "\n",
    "    for i in range(0, 30, 1):\n",
    "        temp_w2c = reconstructor.get_SE3_rotation_y(i)\n",
    "\n",
    "        im, radius = reconstructor.renderer.render(reconstructor.map_param_1, temp_w2c)\n",
    "        im = im[:, 32:352, 32:608]\n",
    "        reconstructor.renderer.save_image(im, current_directory+f'/rotate_demo/{i+16}_render.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始视角(input image的视角)\n",
    "w2c_0 = torch.tensor([\n",
    "                    [1.0, 0.0, 0.0, 0.0],  \n",
    "                    [0.0, 1.0, 0.0, 0.0], \n",
    "                    [0.0, 0.0, 1.0, 0.0], \n",
    "                    [0.0, 0.0, 0.0, 1.0]\n",
    "                ], dtype=torch.float32)\n",
    "\n",
    "# w2c back denotes the transformation matrix for the camera to backward while maintaining the same view angle\n",
    "# 0.2 is roungly the distance (not entirely sure) between the camera and the object, adjust this value to adjust the distance between the camera and the object\n",
    "# If want to combine it with rotation, just multiply the rotation matrix with this matrix\n",
    "backward_distance = 0.2\n",
    "w2c_back = torch.tensor([\n",
    "                    [1.0, 0.0, 0.0, 0.0],  \n",
    "                    [0.0, 1.0, 0.0, 0.0], \n",
    "                    [0.0, 0.0, 1.0, backward_distance], \n",
    "                    [0.0, 0.0, 0.0, 1.0]\n",
    "                ], dtype=torch.float32)\n",
    "\n",
    "# 添加视角，w2c_0为初始视角\n",
    "flash3dreconstructor.w2c.append(w2c_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m rotate_angle \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m angle \u001b[38;5;129;01min\u001b[39;00m rotate_angle:\n\u001b[0;32m----> 4\u001b[0m     rotate_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mflash3dreconstructor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_SE3_rotation_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mangle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     flash3dreconstructor\u001b[38;5;241m.\u001b[39mw2c\u001b[38;5;241m.\u001b[39mappend(rotate_matrix) \u001b[38;5;66;03m# This line to add the rotation matrix to the camera\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# rotate_matrix = flash3dreconstructor.get_SE3_rotation_y(rotate_angle)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# flash3dreconstructor.w2c.append(rotate_matrix) # This line to add the rotation matrix to the camera\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/kf09/lz1278/ANU-COMP8536-2024s2-main/flash3d/generator_test.py:77\u001b[0m, in \u001b[0;36mFlash3DReconstructor.get_SE3_rotation_y\u001b[0;34m(self, theta_degrees)\u001b[0m\n\u001b[1;32m     74\u001b[0m T \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     75\u001b[0m T[:\u001b[38;5;241m3\u001b[39m, :\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m R_y\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/scratch/kf09/lz1278/lyenv/flash3d/lib/python3.11/site-packages/torch/cuda/__init__.py:302\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    301\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 302\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    306\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "# Add the transformation matrix you want to apply to the camera\n",
    "rotate_angle = [10, 20, 30]\n",
    "for angle in rotate_angle:\n",
    "    rotate_matrix = flash3dreconstructor.get_SE3_rotation_y(angle)\n",
    "    flash3dreconstructor.w2c.append(rotate_matrix) # This line to add the rotation matrix to the camera\n",
    "# rotate_matrix = flash3dreconstructor.get_SE3_rotation_y(rotate_angle)\n",
    "# flash3dreconstructor.w2c.append(rotate_matrix) # This line to add the rotation matrix to the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input image, which refers to the very first image of the whole pipeline\n",
    "img = Image.open(intial_img_path).convert(\"RGB\")\n",
    "flash3dreconstructor.check_input_image(img)\n",
    "img = flash3dreconstructor.preprocess(img, dynamic_size=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the current loop index, the loop includes the entire pipeline, from the input image to the final output, it normally depends on the number of transformations\n",
    "# you add to the w2c list of the reconstructor\n",
    "# Note the input image of the first loop (current_loop_index = 0) is the image you prepared above\n",
    "# The output image of the first loop is the input image of the second loop, and so on\n",
    "current_loop_index = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UTastePC\\AppData\\Local\\Temp\\ipykernel_11072\\2593881491.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  updated_tensor = torch.tensor(self.cur_param_1[key]).to('cuda')\n",
      "C:\\Users\\UTastePC\\AppData\\Local\\Temp\\ipykernel_11072\\2593881491.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  updated_tensor = torch.tensor(self.cur_param_2[key]).to('cuda')\n",
      "d:\\Local\\Courses\\COMP8536\\3dgs-utils\\ANU-COMP8536-2024s2\\./flash3d\\renderer.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  w2c = torch.tensor(w2c).cuda().float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as d:\\Local\\Courses\\COMP8536\\3dgs-utils\\ANU-COMP8536-2024s2\\flash3d/imgs/0_0_start_render.png\n",
      "Image saved as d:\\Local\\Courses\\COMP8536\\3dgs-utils\\ANU-COMP8536-2024s2\\flash3d/imgs/0_1_start_render.png\n",
      "Image saved as d:\\Local\\Courses\\COMP8536\\3dgs-utils\\ANU-COMP8536-2024s2\\flash3d/imgs/0_2_start_render.png\n",
      "Image saved as d:\\Local\\Courses\\COMP8536\\3dgs-utils\\ANU-COMP8536-2024s2\\flash3d/imgs/0_3_start_render.png\n",
      "Tracking Iteration 1, Loss: 4552.4761\n",
      "Tracking Iteration 2, Loss: 4954.2080\n",
      "Tracking Iteration 3, Loss: 4494.5562\n",
      "Tracking Iteration 4, Loss: 4348.6875\n",
      "Tracking Iteration 5, Loss: 4247.7188\n",
      "Tracking Iteration 6, Loss: 4126.9707\n",
      "Tracking Iteration 7, Loss: 4036.7437\n",
      "Tracking Iteration 8, Loss: 3974.5220\n",
      "Tracking Iteration 9, Loss: 3909.1885\n",
      "Tracking Iteration 10, Loss: 3849.4834\n",
      "Tracking Iteration 11, Loss: 3795.8528\n",
      "Tracking Iteration 12, Loss: 3749.8350\n",
      "Tracking Iteration 13, Loss: 3707.6917\n",
      "Tracking Iteration 14, Loss: 3667.7437\n",
      "Tracking Iteration 15, Loss: 3634.6392\n",
      "Tracking Iteration 16, Loss: 3601.2886\n",
      "Tracking Iteration 17, Loss: 3569.4473\n",
      "Tracking Iteration 18, Loss: 3542.1687\n",
      "Tracking Iteration 19, Loss: 3517.4558\n",
      "Tracking Iteration 20, Loss: 3490.2080\n",
      "Tracking Iteration 21, Loss: 3466.0518\n",
      "Tracking Iteration 22, Loss: 3445.1526\n",
      "Tracking Iteration 23, Loss: 3420.1184\n",
      "Tracking Iteration 24, Loss: 3396.4163\n",
      "Tracking Iteration 25, Loss: 3376.9458\n",
      "Tracking Iteration 26, Loss: 3359.6064\n",
      "Tracking Iteration 27, Loss: 3344.4385\n",
      "Tracking Iteration 28, Loss: 3329.9236\n",
      "Tracking Iteration 29, Loss: 3315.4282\n",
      "Tracking Iteration 30, Loss: 3298.4233\n",
      "Tracking Iteration 31, Loss: 3285.9429\n",
      "Tracking Iteration 32, Loss: 3271.0840\n",
      "Tracking Iteration 33, Loss: 3257.5015\n",
      "Tracking Iteration 34, Loss: 3242.3057\n",
      "Tracking Iteration 35, Loss: 3227.0259\n",
      "Tracking Iteration 36, Loss: 3216.2185\n",
      "Tracking Iteration 37, Loss: 3206.4451\n",
      "Tracking Iteration 38, Loss: 3192.9116\n",
      "Tracking Iteration 39, Loss: 3179.4912\n",
      "Tracking Iteration 40, Loss: 3165.9309\n",
      "Tracking Iteration 41, Loss: 3156.0188\n",
      "Tracking Iteration 42, Loss: 3145.8684\n",
      "Tracking Iteration 43, Loss: 3137.0796\n",
      "Tracking Iteration 44, Loss: 3126.1978\n",
      "Tracking Iteration 45, Loss: 3117.8337\n",
      "Tracking Iteration 46, Loss: 3106.5532\n",
      "Tracking Iteration 47, Loss: 3100.0210\n",
      "Tracking Iteration 48, Loss: 3090.7329\n",
      "Tracking Iteration 49, Loss: 3081.4785\n",
      "Tracking Iteration 50, Loss: 3072.5479\n",
      "Tracking Iteration 51, Loss: 3063.6606\n",
      "Tracking Iteration 52, Loss: 3056.2271\n",
      "Tracking Iteration 53, Loss: 3050.1802\n",
      "Tracking Iteration 54, Loss: 3044.9875\n",
      "Tracking Iteration 55, Loss: 3035.7031\n",
      "Tracking Iteration 56, Loss: 3028.6121\n",
      "Tracking Iteration 57, Loss: 3018.5071\n",
      "Tracking Iteration 58, Loss: 3010.7861\n",
      "Tracking Iteration 59, Loss: 3001.8491\n",
      "Tracking Iteration 60, Loss: 2997.9922\n",
      "Tracking Iteration 61, Loss: 2991.4128\n",
      "Tracking Iteration 62, Loss: 2982.9348\n",
      "Tracking Iteration 63, Loss: 2978.7378\n",
      "Tracking Iteration 64, Loss: 2972.5669\n",
      "Tracking Iteration 65, Loss: 2962.1748\n",
      "Tracking Iteration 66, Loss: 2957.4761\n",
      "Tracking Iteration 67, Loss: 2960.1064\n",
      "Tracking Iteration 68, Loss: 2950.5688\n",
      "Tracking Iteration 69, Loss: 2944.0381\n",
      "Tracking Iteration 70, Loss: 2935.7485\n",
      "Tracking Iteration 71, Loss: 2934.0366\n",
      "Tracking Iteration 72, Loss: 2929.9280\n",
      "Tracking Iteration 73, Loss: 2925.6501\n",
      "Tracking Iteration 74, Loss: 2923.4810\n",
      "Tracking Iteration 75, Loss: 2920.2969\n",
      "Tracking Iteration 76, Loss: 2915.1455\n",
      "Tracking Iteration 77, Loss: 2907.2358\n",
      "Tracking Iteration 78, Loss: 2904.8579\n",
      "Tracking Iteration 79, Loss: 2902.6443\n",
      "Tracking Iteration 80, Loss: 2894.4165\n",
      "Tracking Iteration 81, Loss: 2888.4856\n",
      "Tracking Iteration 82, Loss: 2883.8091\n",
      "Tracking Iteration 83, Loss: 2876.3823\n",
      "Tracking Iteration 84, Loss: 2873.8430\n",
      "Tracking Iteration 85, Loss: 2869.0295\n",
      "Tracking Iteration 86, Loss: 2866.2500\n",
      "Tracking Iteration 87, Loss: 2861.2192\n",
      "Tracking Iteration 88, Loss: 2859.0759\n",
      "Tracking Iteration 89, Loss: 2854.9558\n",
      "Tracking Iteration 90, Loss: 2852.9917\n",
      "Tracking Iteration 91, Loss: 2846.9604\n",
      "Tracking Iteration 92, Loss: 2840.2974\n",
      "Tracking Iteration 93, Loss: 2836.4453\n",
      "Tracking Iteration 94, Loss: 2832.5234\n",
      "Tracking Iteration 95, Loss: 2830.0486\n",
      "Tracking Iteration 96, Loss: 2822.7886\n",
      "Tracking Iteration 97, Loss: 2820.7612\n",
      "Tracking Iteration 98, Loss: 2821.9927\n",
      "Tracking Iteration 99, Loss: 2819.3918\n",
      "Image saved as d:\\Local\\Courses\\COMP8536\\3dgs-utils\\ANU-COMP8536-2024s2\\flash3d/imgs/0_0_end_render.png\n",
      "Image saved as d:\\Local\\Courses\\COMP8536\\3dgs-utils\\ANU-COMP8536-2024s2\\flash3d/imgs/0_1_end_render.png\n",
      "Image saved as d:\\Local\\Courses\\COMP8536\\3dgs-utils\\ANU-COMP8536-2024s2\\flash3d/imgs/0_2_end_render.png\n",
      "Image saved as d:\\Local\\Courses\\COMP8536\\3dgs-utils\\ANU-COMP8536-2024s2\\flash3d/imgs/0_3_end_render.png\n",
      "Tracking Iteration 100, Loss: 2813.3967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianPredictor(\n",
       "  (models): ModuleDict(\n",
       "    (unidepth_extended): UniDepthExtended(\n",
       "      (unidepth): UniDepthDepth(\n",
       "        (depth_prediction_model): UniDepthV1(\n",
       "          (pixel_encoder): DinoVisionTransformer(\n",
       "            (patch_embed): PatchEmbed(\n",
       "              (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
       "              (norm): Identity()\n",
       "            )\n",
       "            (blocks): ModuleList(\n",
       "              (0-23): 24 x NestedTensorBlock(\n",
       "                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "                (attn): MemEffAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (ls1): LayerScale()\n",
       "                (drop_path1): Identity()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (ls2): LayerScale()\n",
       "                (drop_path2): Identity()\n",
       "              )\n",
       "            )\n",
       "            (head): Identity()\n",
       "          )\n",
       "          (pixel_decoder): Decoder(\n",
       "            (input_adapter): ListAdapter(\n",
       "              (input_adapters): ModuleList(\n",
       "                (0-3): 4 x Sequential(\n",
       "                  (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "                  (2): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (token_adapter): ListAdapter(\n",
       "              (input_adapters): ModuleList(\n",
       "                (0-3): 4 x Sequential(\n",
       "                  (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "                  (2): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (camera_layer): CameraHead(\n",
       "              (aggregate): AttentionBlock(\n",
       "                (mlp): MLP(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (proj1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (proj2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (dropout): Identity()\n",
       "                )\n",
       "                (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (norm_attnx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm_attnctx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (ls1): LayerScale()\n",
       "                (ls2): LayerScale()\n",
       "              )\n",
       "              (layers): ModuleList(\n",
       "                (0-1): 2 x AttentionBlock(\n",
       "                  (mlp): MLP(\n",
       "                    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                    (proj1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (proj2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (dropout): Identity()\n",
       "                  )\n",
       "                  (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                  (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (norm_attnx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm_attnctx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (ls1): LayerScale()\n",
       "                  (ls2): LayerScale()\n",
       "                )\n",
       "              )\n",
       "              (in_features): MLP(\n",
       "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (proj1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                (proj2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (dropout): Identity()\n",
       "              )\n",
       "              (out): MLP(\n",
       "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (proj1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                (proj2): Linear(in_features=1024, out_features=1, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (dropout): Identity()\n",
       "              )\n",
       "              (cls_project): Sequential(\n",
       "                (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "                (2): GELU(approximate='none')\n",
       "                (3): Linear(in_features=256, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (depth_layer): DepthHead(\n",
       "              (project_rays16): MLP(\n",
       "                (norm): LayerNorm((81,), eps=1e-05, elementwise_affine=True)\n",
       "                (proj1): Linear(in_features=81, out_features=324, bias=True)\n",
       "                (proj2): Linear(in_features=324, out_features=512, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (dropout): Identity()\n",
       "              )\n",
       "              (project_rays8): MLP(\n",
       "                (norm): LayerNorm((81,), eps=1e-05, elementwise_affine=True)\n",
       "                (proj1): Linear(in_features=81, out_features=324, bias=True)\n",
       "                (proj2): Linear(in_features=324, out_features=256, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (dropout): Identity()\n",
       "              )\n",
       "              (project_rays4): MLP(\n",
       "                (norm): LayerNorm((81,), eps=1e-05, elementwise_affine=True)\n",
       "                (proj1): Linear(in_features=81, out_features=324, bias=True)\n",
       "                (proj2): Linear(in_features=324, out_features=128, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (dropout): Identity()\n",
       "              )\n",
       "              (to_latents): MLP(\n",
       "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (proj1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                (proj2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (dropout): Identity()\n",
       "              )\n",
       "              (features_channel_cat): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (up8): ConvUpsample(\n",
       "                (convs): ModuleList(\n",
       "                  (0-1): 2 x CvnxtBlock(\n",
       "                    (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=512)\n",
       "                    (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "                    (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (up): Sequential(\n",
       "                  (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       "                  (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                )\n",
       "              )\n",
       "              (up4): ConvUpsample(\n",
       "                (convs): ModuleList(\n",
       "                  (0-1): 2 x CvnxtBlock(\n",
       "                    (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=256)\n",
       "                    (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "                    (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (up): Sequential(\n",
       "                  (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       "                  (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                )\n",
       "              )\n",
       "              (up2): ConvUpsample(\n",
       "                (convs): ModuleList(\n",
       "                  (0-1): 2 x CvnxtBlock(\n",
       "                    (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=128)\n",
       "                    (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "                    (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (up): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       "                  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                )\n",
       "              )\n",
       "              (layers_16): ModuleList(\n",
       "                (0-2): 3 x AttentionBlock(\n",
       "                  (mlp): MLP(\n",
       "                    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                    (proj1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (proj2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (dropout): Identity()\n",
       "                  )\n",
       "                  (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                  (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (norm_attnx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm_attnctx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (ls1): LayerScale()\n",
       "                  (ls2): LayerScale()\n",
       "                )\n",
       "              )\n",
       "              (layers_8): ModuleList(\n",
       "                (0-1): 2 x NystromBlock(\n",
       "                  (mlp): MLP(\n",
       "                    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                    (proj1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                    (proj2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (dropout): Identity()\n",
       "                  )\n",
       "                  (kv): Linear(in_features=256, out_features=512, bias=True)\n",
       "                  (q): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (norm_attnx): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm_attnctx): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (out): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (ls1): LayerScale()\n",
       "                  (ls2): LayerScale()\n",
       "                  (attention_fn): NystromAttention(\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (landmark_pooling): AvgPool()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (layers_4): ModuleList(\n",
       "                (0): NystromBlock(\n",
       "                  (mlp): MLP(\n",
       "                    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                    (proj1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                    (proj2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (dropout): Identity()\n",
       "                  )\n",
       "                  (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "                  (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (norm_attnx): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm_attnctx): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (out): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (ls1): LayerScale()\n",
       "                  (ls2): LayerScale()\n",
       "                  (attention_fn): NystromAttention(\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (landmark_pooling): AvgPool()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (aggregate_16): AttentionBlock(\n",
       "                (mlp): MLP(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (proj1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (proj2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (dropout): Identity()\n",
       "                )\n",
       "                (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (norm_attnx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm_attnctx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (ls1): LayerScale()\n",
       "                (ls2): LayerScale()\n",
       "              )\n",
       "              (prompt_camera): AttentionBlock(\n",
       "                (mlp): MLP(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (proj1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (proj2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (dropout): Identity()\n",
       "                )\n",
       "                (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (norm_attnx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm_attnctx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (ls1): LayerScale()\n",
       "                (ls2): LayerScale()\n",
       "              )\n",
       "              (out2): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (out4): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (out8): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (pos_embed): Positional encoding PositionEmbeddingSine\n",
       "                num_pos_feats: 256\n",
       "                temperature: 10000\n",
       "                normalize: True\n",
       "                scale: 6.283185307179586\n",
       "            (level_embed_layer): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (encoder): ResnetEncoder(\n",
       "        (encoder): ResNet(\n",
       "          (conv1): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (layer1): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer2): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer3): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (4): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (5): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer4): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "          (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (models): ModuleDict(\n",
       "        (depth): DepthDecoder(\n",
       "          (decoder): ModuleList(\n",
       "            (0): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (1): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(1280, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (2): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (3): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(640, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (4): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (5): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (6): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (7): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (8): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (9): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (10): Conv3x3(\n",
       "              (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (conv): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "            (11): Conv3x3(\n",
       "              (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (conv): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "            (12): Conv3x3(\n",
       "              (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (conv): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "            (13): Conv3x3(\n",
       "              (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (conv): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (gauss_decoder_0): GaussianDecoder(\n",
       "          (out): Conv2d(32, 23, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (decoder): ModuleList(\n",
       "            (0): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (1): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(1280, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (2): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (3): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(640, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (4): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (5): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (6): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (7): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (8-9): 2 x ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (gauss_decoder_1): GaussianDecoder(\n",
       "          (out): Conv2d(32, 23, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (decoder): ModuleList(\n",
       "            (0): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (1): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(1280, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (2): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (3): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(640, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (4): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (5): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (6): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (7): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (8-9): 2 x ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (backproject_depth): ModuleDict(\n",
       "    (0): BackprojectDepth()\n",
       "    (1): BackprojectDepth()\n",
       "    (2): BackprojectDepth()\n",
       "    (3): BackprojectDepth()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flash3dreconstructor.model.to('cuda')\n",
    "\n",
    "outputs, outputs_1_gauss = flash3dreconstructor.flash3d_postprocess(current_loop_index, img)\n",
    "if current_loop_index == 0:\n",
    "    flash3dreconstructor.flash3d_initial_map(outputs, outputs_1_gauss)\n",
    "else:\n",
    "    flash3dreconstructor.flash3d_additional_map(current_loop_index, outputs, outputs_1_gauss)\n",
    "\n",
    "if current_loop_index + 1 < len(flash3dreconstructor.w2c):\n",
    "    mask_render_path_diffusion, mask_path_diffusion = flash3dreconstructor.flash3d_prepare_img_mask_for_diffusion(current_loop_index)\n",
    "\n",
    "flash3dreconstructor.model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the render image and mask image\n",
    "if current_loop_index + 1 < len(flash3dreconstructor.w2c):\n",
    "    rendered_img = Image.open(mask_render_path_diffusion)\n",
    "    mask_img = Image.open(mask_path_diffusion)\n",
    "\n",
    "    grid_img = make_image_grid([rendered_img, mask_img], rows=1, cols=2)\n",
    "    plt.imshow(grid_img)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'./imgs/before_inpainting_{current_loop_index}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt_diffusion = 'A indoor scene, a room, a window, two sofas.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if current_loop_index + 1 < len(flash3dreconstructor.w2c):\n",
    "    diffusion_img = generate_diffusion_img(image_path=mask_render_path_diffusion, mask_path=mask_path_diffusion,\n",
    "                                                    prompt_question=None,\n",
    "                                                    prompt_diffusion=Prompt_diffusion,\n",
    "                                                    base_model='stable-diffusion-v2', index=current_loop_index, strength=1.0,\n",
    "                                                    negative_prompt=\"bad architecture, inconsistent, poor details, blurry\") # 512*512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the diffusion image\n",
    "if current_loop_index + 1 < len(flash3dreconstructor.w2c):\n",
    "    plt.imshow(diffusion_img)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'./imgs/diffusion_{current_loop_index}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianPredictor(\n",
       "  (models): ModuleDict(\n",
       "    (unidepth_extended): UniDepthExtended(\n",
       "      (unidepth): UniDepthDepth(\n",
       "        (depth_prediction_model): UniDepthV1(\n",
       "          (pixel_encoder): DinoVisionTransformer(\n",
       "            (patch_embed): PatchEmbed(\n",
       "              (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
       "              (norm): Identity()\n",
       "            )\n",
       "            (blocks): ModuleList(\n",
       "              (0-23): 24 x NestedTensorBlock(\n",
       "                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "                (attn): MemEffAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (ls1): LayerScale()\n",
       "                (drop_path1): Identity()\n",
       "                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "                (mlp): Mlp(\n",
       "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  (drop): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (ls2): LayerScale()\n",
       "                (drop_path2): Identity()\n",
       "              )\n",
       "            )\n",
       "            (head): Identity()\n",
       "          )\n",
       "          (pixel_decoder): Decoder(\n",
       "            (input_adapter): ListAdapter(\n",
       "              (input_adapters): ModuleList(\n",
       "                (0-3): 4 x Sequential(\n",
       "                  (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "                  (2): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (token_adapter): ListAdapter(\n",
       "              (input_adapters): ModuleList(\n",
       "                (0-3): 4 x Sequential(\n",
       "                  (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "                  (2): GELU(approximate='none')\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (camera_layer): CameraHead(\n",
       "              (aggregate): AttentionBlock(\n",
       "                (mlp): MLP(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (proj1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (proj2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (dropout): Identity()\n",
       "                )\n",
       "                (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (norm_attnx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm_attnctx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (ls1): LayerScale()\n",
       "                (ls2): LayerScale()\n",
       "              )\n",
       "              (layers): ModuleList(\n",
       "                (0-1): 2 x AttentionBlock(\n",
       "                  (mlp): MLP(\n",
       "                    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                    (proj1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (proj2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (dropout): Identity()\n",
       "                  )\n",
       "                  (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                  (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (norm_attnx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm_attnctx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (ls1): LayerScale()\n",
       "                  (ls2): LayerScale()\n",
       "                )\n",
       "              )\n",
       "              (in_features): MLP(\n",
       "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (proj1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                (proj2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (dropout): Identity()\n",
       "              )\n",
       "              (out): MLP(\n",
       "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (proj1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                (proj2): Linear(in_features=1024, out_features=1, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (dropout): Identity()\n",
       "              )\n",
       "              (cls_project): Sequential(\n",
       "                (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "                (2): GELU(approximate='none')\n",
       "                (3): Linear(in_features=256, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (depth_layer): DepthHead(\n",
       "              (project_rays16): MLP(\n",
       "                (norm): LayerNorm((81,), eps=1e-05, elementwise_affine=True)\n",
       "                (proj1): Linear(in_features=81, out_features=324, bias=True)\n",
       "                (proj2): Linear(in_features=324, out_features=512, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (dropout): Identity()\n",
       "              )\n",
       "              (project_rays8): MLP(\n",
       "                (norm): LayerNorm((81,), eps=1e-05, elementwise_affine=True)\n",
       "                (proj1): Linear(in_features=81, out_features=324, bias=True)\n",
       "                (proj2): Linear(in_features=324, out_features=256, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (dropout): Identity()\n",
       "              )\n",
       "              (project_rays4): MLP(\n",
       "                (norm): LayerNorm((81,), eps=1e-05, elementwise_affine=True)\n",
       "                (proj1): Linear(in_features=81, out_features=324, bias=True)\n",
       "                (proj2): Linear(in_features=324, out_features=128, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (dropout): Identity()\n",
       "              )\n",
       "              (to_latents): MLP(\n",
       "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (proj1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                (proj2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (dropout): Identity()\n",
       "              )\n",
       "              (features_channel_cat): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (up8): ConvUpsample(\n",
       "                (convs): ModuleList(\n",
       "                  (0-1): 2 x CvnxtBlock(\n",
       "                    (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=512)\n",
       "                    (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "                    (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (up): Sequential(\n",
       "                  (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       "                  (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                )\n",
       "              )\n",
       "              (up4): ConvUpsample(\n",
       "                (convs): ModuleList(\n",
       "                  (0-1): 2 x CvnxtBlock(\n",
       "                    (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=256)\n",
       "                    (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "                    (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (up): Sequential(\n",
       "                  (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       "                  (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                )\n",
       "              )\n",
       "              (up2): ConvUpsample(\n",
       "                (convs): ModuleList(\n",
       "                  (0-1): 2 x CvnxtBlock(\n",
       "                    (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=128)\n",
       "                    (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "                    (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (up): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): UpsamplingBilinear2d(scale_factor=2.0, mode='bilinear')\n",
       "                  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                )\n",
       "              )\n",
       "              (layers_16): ModuleList(\n",
       "                (0-2): 3 x AttentionBlock(\n",
       "                  (mlp): MLP(\n",
       "                    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                    (proj1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (proj2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (dropout): Identity()\n",
       "                  )\n",
       "                  (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                  (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (norm_attnx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm_attnctx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (ls1): LayerScale()\n",
       "                  (ls2): LayerScale()\n",
       "                )\n",
       "              )\n",
       "              (layers_8): ModuleList(\n",
       "                (0-1): 2 x NystromBlock(\n",
       "                  (mlp): MLP(\n",
       "                    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                    (proj1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                    (proj2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (dropout): Identity()\n",
       "                  )\n",
       "                  (kv): Linear(in_features=256, out_features=512, bias=True)\n",
       "                  (q): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (norm_attnx): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm_attnctx): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (out): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (ls1): LayerScale()\n",
       "                  (ls2): LayerScale()\n",
       "                  (attention_fn): NystromAttention(\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (landmark_pooling): AvgPool()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (layers_4): ModuleList(\n",
       "                (0): NystromBlock(\n",
       "                  (mlp): MLP(\n",
       "                    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                    (proj1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                    (proj2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (dropout): Identity()\n",
       "                  )\n",
       "                  (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "                  (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (norm_attnx): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (norm_attnctx): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (out): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (ls1): LayerScale()\n",
       "                  (ls2): LayerScale()\n",
       "                  (attention_fn): NystromAttention(\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (landmark_pooling): AvgPool()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (aggregate_16): AttentionBlock(\n",
       "                (mlp): MLP(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (proj1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (proj2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (dropout): Identity()\n",
       "                )\n",
       "                (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (norm_attnx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm_attnctx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (ls1): LayerScale()\n",
       "                (ls2): LayerScale()\n",
       "              )\n",
       "              (prompt_camera): AttentionBlock(\n",
       "                (mlp): MLP(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (proj1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (proj2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (dropout): Identity()\n",
       "                )\n",
       "                (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "                (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (norm_attnx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (norm_attnctx): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (ls1): LayerScale()\n",
       "                (ls2): LayerScale()\n",
       "              )\n",
       "              (out2): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (out4): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (out8): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (pos_embed): Positional encoding PositionEmbeddingSine\n",
       "                num_pos_feats: 256\n",
       "                temperature: 10000\n",
       "                normalize: True\n",
       "                scale: 6.283185307179586\n",
       "            (level_embed_layer): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (encoder): ResnetEncoder(\n",
       "        (encoder): ResNet(\n",
       "          (conv1): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (layer1): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer2): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer3): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (4): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (5): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer4): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "          (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (models): ModuleDict(\n",
       "        (depth): DepthDecoder(\n",
       "          (decoder): ModuleList(\n",
       "            (0): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (1): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(1280, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (2): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (3): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(640, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (4): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (5): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (6): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (7): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (8): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (9): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (10): Conv3x3(\n",
       "              (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (conv): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "            (11): Conv3x3(\n",
       "              (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (conv): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "            (12): Conv3x3(\n",
       "              (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (conv): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "            (13): Conv3x3(\n",
       "              (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (conv): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (gauss_decoder_0): GaussianDecoder(\n",
       "          (out): Conv2d(32, 23, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (decoder): ModuleList(\n",
       "            (0): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (1): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(1280, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (2): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (3): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(640, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (4): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (5): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (6): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (7): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (8-9): 2 x ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (gauss_decoder_1): GaussianDecoder(\n",
       "          (out): Conv2d(32, 23, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (decoder): ModuleList(\n",
       "            (0): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (1): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(1280, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (2): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (3): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(640, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (4): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (5): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (6): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (7): ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "            (8-9): 2 x ConvBlock(\n",
       "              (conv): Conv3x3(\n",
       "                (pad): ReflectionPad2d((1, 1, 1, 1))\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "              )\n",
       "              (nonlin): ELU(alpha=1.0, inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (backproject_depth): ModuleDict(\n",
       "    (0): BackprojectDepth()\n",
       "    (1): BackprojectDepth()\n",
       "    (2): BackprojectDepth()\n",
       "    (3): BackprojectDepth()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flash3dreconstructor.model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocess the diffusion image\n",
    "flash3dreconstructor.flash3d_post_process_diffusion_img(diffusion_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Stop Here",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStop Here\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Stop Here"
     ]
    }
   ],
   "source": [
    "raise ValueError('Stop Here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as d:\\Local\\Courses\\COMP8536\\3dgs-utils\\ANU-COMP8536-2024s2\\flash3d/imgs/0_0_start_render.png\n",
      "Image saved as d:\\Local\\Courses\\COMP8536\\3dgs-utils\\ANU-COMP8536-2024s2\\flash3d/imgs/0_1_start_render.png\n",
      "Image saved as d:\\Local\\Courses\\COMP8536\\3dgs-utils\\ANU-COMP8536-2024s2\\flash3d/imgs/0_2_start_render.png\n",
      "Image saved as d:\\Local\\Courses\\COMP8536\\3dgs-utils\\ANU-COMP8536-2024s2\\flash3d/imgs/0_3_start_render.png\n",
      "Tracking Iteration 1, Loss: 111754.4844\n",
      "Tracking Iteration 2, Loss: 103192.8438\n",
      "Tracking Iteration 3, Loss: 92774.3828\n",
      "Tracking Iteration 4, Loss: 81474.3750\n",
      "Tracking Iteration 5, Loss: 70132.5000\n",
      "Tracking Iteration 6, Loss: 59640.6094\n",
      "Tracking Iteration 7, Loss: 50654.8711\n",
      "Tracking Iteration 8, Loss: 43435.9297\n",
      "Tracking Iteration 9, Loss: 37905.4297\n",
      "Tracking Iteration 10, Loss: 33802.8203\n",
      "Tracking Iteration 11, Loss: 30790.3516\n",
      "Tracking Iteration 12, Loss: 28571.1602\n",
      "Tracking Iteration 13, Loss: 26914.5469\n",
      "Tracking Iteration 14, Loss: 25650.1621\n",
      "Tracking Iteration 15, Loss: 24673.9570\n",
      "Tracking Iteration 16, Loss: 23903.1992\n",
      "Tracking Iteration 17, Loss: 23282.0410\n",
      "Tracking Iteration 18, Loss: 22766.5879\n",
      "Tracking Iteration 19, Loss: 22321.4277\n",
      "Tracking Iteration 20, Loss: 21922.4414\n",
      "Tracking Iteration 21, Loss: 21558.2012\n",
      "Tracking Iteration 22, Loss: 21213.5918\n",
      "Tracking Iteration 23, Loss: 20886.3945\n",
      "Tracking Iteration 24, Loss: 20570.1191\n",
      "Tracking Iteration 25, Loss: 20261.4395\n",
      "Tracking Iteration 26, Loss: 19965.1680\n",
      "Tracking Iteration 27, Loss: 19668.8750\n",
      "Tracking Iteration 28, Loss: 19382.0801\n",
      "Tracking Iteration 29, Loss: 19096.0645\n",
      "Tracking Iteration 30, Loss: 18817.7754\n",
      "Tracking Iteration 31, Loss: 18544.5059\n",
      "Tracking Iteration 32, Loss: 18273.7969\n",
      "Tracking Iteration 33, Loss: 18007.0547\n",
      "Tracking Iteration 34, Loss: 17746.2480\n",
      "Tracking Iteration 35, Loss: 17488.7422\n",
      "Tracking Iteration 36, Loss: 17235.7168\n",
      "Tracking Iteration 37, Loss: 16983.9336\n",
      "Tracking Iteration 38, Loss: 16736.0312\n",
      "Tracking Iteration 39, Loss: 16491.0684\n",
      "Tracking Iteration 40, Loss: 16246.0146\n",
      "Tracking Iteration 41, Loss: 16008.4629\n",
      "Tracking Iteration 42, Loss: 15772.7598\n",
      "Tracking Iteration 43, Loss: 15540.7568\n",
      "Tracking Iteration 44, Loss: 15313.5713\n",
      "Tracking Iteration 45, Loss: 15087.9941\n",
      "Tracking Iteration 46, Loss: 14866.9912\n",
      "Tracking Iteration 47, Loss: 14649.6641\n",
      "Tracking Iteration 48, Loss: 14437.1162\n",
      "Tracking Iteration 49, Loss: 14223.4346\n",
      "Tracking Iteration 50, Loss: 14013.7031\n",
      "Tracking Iteration 51, Loss: 13808.7422\n",
      "Tracking Iteration 52, Loss: 13603.9395\n",
      "Tracking Iteration 53, Loss: 13403.3701\n",
      "Tracking Iteration 54, Loss: 13204.3848\n",
      "Tracking Iteration 55, Loss: 13013.7246\n",
      "Tracking Iteration 56, Loss: 12826.1504\n",
      "Tracking Iteration 57, Loss: 12643.4287\n",
      "Tracking Iteration 58, Loss: 12458.3213\n",
      "Tracking Iteration 59, Loss: 12283.1172\n",
      "Tracking Iteration 60, Loss: 12106.4443\n",
      "Tracking Iteration 61, Loss: 11932.0518\n",
      "Tracking Iteration 62, Loss: 11760.2930\n",
      "Tracking Iteration 63, Loss: 11587.6074\n",
      "Tracking Iteration 64, Loss: 11423.0840\n",
      "Tracking Iteration 65, Loss: 11256.7793\n",
      "Tracking Iteration 66, Loss: 11094.9160\n",
      "Tracking Iteration 67, Loss: 10935.1221\n",
      "Tracking Iteration 68, Loss: 10775.4756\n",
      "Tracking Iteration 69, Loss: 10620.4668\n",
      "Tracking Iteration 70, Loss: 10464.2598\n",
      "Tracking Iteration 71, Loss: 10310.4961\n",
      "Tracking Iteration 72, Loss: 10160.5742\n",
      "Tracking Iteration 73, Loss: 10012.2842\n",
      "Tracking Iteration 74, Loss: 9866.8730\n",
      "Tracking Iteration 75, Loss: 9723.6553\n",
      "Tracking Iteration 76, Loss: 9580.2012\n",
      "Tracking Iteration 77, Loss: 9438.0781\n",
      "Tracking Iteration 78, Loss: 9301.2373\n",
      "Tracking Iteration 79, Loss: 9166.4668\n",
      "Tracking Iteration 80, Loss: 9033.0732\n",
      "Tracking Iteration 81, Loss: 8897.8867\n",
      "Tracking Iteration 82, Loss: 8763.9170\n",
      "Tracking Iteration 83, Loss: 8640.1719\n",
      "Tracking Iteration 84, Loss: 8516.4980\n",
      "Tracking Iteration 85, Loss: 8393.2354\n",
      "Tracking Iteration 86, Loss: 8270.1328\n",
      "Tracking Iteration 87, Loss: 8148.4028\n",
      "Tracking Iteration 88, Loss: 8027.9365\n",
      "Tracking Iteration 89, Loss: 7911.3623\n",
      "Tracking Iteration 90, Loss: 7800.2705\n",
      "Tracking Iteration 91, Loss: 7689.6475\n",
      "Tracking Iteration 92, Loss: 7579.1147\n",
      "Tracking Iteration 93, Loss: 7469.6426\n",
      "Tracking Iteration 94, Loss: 7372.1343\n",
      "Tracking Iteration 95, Loss: 7272.6660\n",
      "Tracking Iteration 96, Loss: 7174.1006\n",
      "Tracking Iteration 97, Loss: 7080.2197\n",
      "Tracking Iteration 98, Loss: 6987.8770\n",
      "Tracking Iteration 99, Loss: 6899.7271\n",
      "Image saved as d:\\Local\\Courses\\COMP8536\\3dgs-utils\\ANU-COMP8536-2024s2\\flash3d/imgs/0_0_end_render.png\n",
      "Image saved as d:\\Local\\Courses\\COMP8536\\3dgs-utils\\ANU-COMP8536-2024s2\\flash3d/imgs/0_1_end_render.png\n",
      "Image saved as d:\\Local\\Courses\\COMP8536\\3dgs-utils\\ANU-COMP8536-2024s2\\flash3d/imgs/0_2_end_render.png\n",
      "Image saved as d:\\Local\\Courses\\COMP8536\\3dgs-utils\\ANU-COMP8536-2024s2\\flash3d/imgs/0_3_end_render.png\n",
      "Tracking Iteration 100, Loss: 6815.5752\n",
      "Image saved as ./flash3d-cache/rotate_demo/0_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/1_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/2_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/3_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/4_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/5_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/6_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/7_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/8_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/9_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/10_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/11_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/12_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/13_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/14_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/15_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/16_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/17_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/18_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/19_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/20_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/21_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/22_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/23_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/24_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/25_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/26_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/27_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/28_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/29_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/30_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/31_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/32_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/33_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/34_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/35_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/36_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/37_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/38_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/39_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/40_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/41_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/42_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/43_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/44_render.png\n",
      "Image saved as ./flash3d-cache/rotate_demo/45_render.png\n"
     ]
    }
   ],
   "source": [
    "flash3dreconstructor.flash3d_final_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
